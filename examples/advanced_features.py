"""
Advanced SciAgent Features Demo

Demonstrates the full power of SciAgent:
- MCP integration for literature search
- Knowledge graph for scientific knowledge
- Thompson sampling for hypothesis exploration
- MCTS for experiment planning
- Bayesian experimental design for refinements
"""

import asyncio
from pathlib import Path

from sciagent import SciAgent
from sciagent.project.knowledge_graph import ScientificKnowledgeGraph
from sciagent.advanced import (
    BayesianExperimentSelector,
    MCTSPlanner,
    ThompsonSamplingExplorer,
    ExperimentCandidate,
)
from sciagent.utils.models import Hypothesis, ExperimentDesign


async def demo_full_workflow():
    """
    Complete workflow showing all advanced features
    """

    print("=" * 70)
    print("SciAgent Advanced Features Demo")
    print("=" * 70)
    print()

    # Initialize SciAgent
    agent = SciAgent()

    # Research question
    query = """
    Investigate whether self-attention mechanisms in transformers
    exhibit specialization across different attention heads
    """

    print(f"Research Question: {query}\n")

    # =================================================================
    # PART 1: Run Experiment with All Advanced Features
    # =================================================================

    print("\n" + "=" * 70)
    print("PART 1: Running Experiment with Advanced Features")
    print("=" * 70)

    result = await agent.run(
        query=query,
        interactive=False,  # Automated for demo
    )

    print(f"\n✓ Experiment completed: {result.experiment_id}")
    print(f"  Status: {result.state.status.value}")
    print(f"  Hypothesis: {result.planning.recommendation.hypothesis.statement[:80]}...")

    # Show papers found via MCP
    print(f"\n  Papers found via MCP: {len(result.planning.papers)}")
    for i, paper in enumerate(result.planning.papers[:3], 1):
        print(f"    {i}. {paper.title}")

    # Show hypotheses generated by Thompson sampling
    print(f"\n  Hypotheses explored: {len(result.planning.hypotheses)}")
    for i, hyp in enumerate(result.planning.hypotheses[:3], 1):
        print(f"    {i}. {hyp.statement[:60]}...")

    # Show experiment sequence planned by MCTS
    sequence = result.planning.recommendation.sequence
    print(f"\n  Experiment sequence (MCTS):")
    print(f"    Steps: {len(sequence.steps)}")
    print(f"    Expected value: {sequence.total_value:.3f}")
    print(f"    Expected cost: ${sequence.expected_cost:.2f}")

    # =================================================================
    # PART 2: Knowledge Graph Exploration
    # =================================================================

    print("\n" + "=" * 70)
    print("PART 2: Knowledge Graph Exploration")
    print("=" * 70)

    # Access knowledge graph
    kg = agent.coordinator.agents["science"].knowledge_graph

    # Get statistics
    stats = kg.get_statistics()
    print(f"\nKnowledge Graph Statistics:")
    for key, value in stats.items():
        print(f"  {key}: {value}")

    # Query related papers
    related_papers = kg.query_related_papers("attention mechanisms", limit=5)
    print(f"\nRelated papers in knowledge graph: {len(related_papers)}")
    for paper in related_papers[:3]:
        print(f"  - {paper.get('title', 'Unknown')}")

    # Visualize knowledge graph
    output_path = Path("knowledge_graph_visualization.png")
    kg.visualize(output_path)
    print(f"\n✓ Knowledge graph visualized: {output_path}")

    # =================================================================
    # PART 3: Thompson Sampling for Hypothesis Exploration
    # =================================================================

    print("\n" + "=" * 70)
    print("PART 3: Thompson Sampling Demo")
    print("=" * 70)

    explorer = ThompsonSamplingExplorer()

    # Explore hypothesis space
    hypotheses = await explorer.explore(
        query="attention head specialization",
        papers=result.planning.papers,
        n_iterations=30,
    )

    print(f"\nExplored {len(hypotheses)} hypotheses")
    print("\nTop 5 by expected value:")
    for i, h_stats in enumerate(hypotheses[:5], 1):
        print(f"  {i}. EV={h_stats.expected_value:.3f} | "
              f"Uncertainty={h_stats.uncertainty:.3f}")
        print(f"     {h_stats.hypothesis.statement[:70]}...")

    # Get exploration statistics
    exp_stats = explorer.get_statistics()
    print(f"\nExploration Statistics:")
    for key, value in exp_stats.items():
        print(f"  {key}: {value}")

    # =================================================================
    # PART 4: MCTS Experiment Planning
    # =================================================================

    print("\n" + "=" * 70)
    print("PART 4: MCTS Experiment Planning")
    print("=" * 70)

    planner = MCTSPlanner(n_simulations=50, max_depth=4)

    # Plan experiments for top hypothesis
    top_hypothesis = hypotheses[0].hypothesis

    initial_design = ExperimentDesign(
        description="Test attention head specialization",
        measurements=["attention_entropy", "head_correlation"],
        controls=["random_attention", "uniform_attention"],
        sample_size=1000,
        statistical_tests=["anova", "post_hoc"],
        potential_confounds=["model_size", "training_data"],
        success_criteria="p < 0.01 and effect_size > 0.3",
    )

    sequence = await planner.plan(
        hypothesis=top_hypothesis,
        initial_design=initial_design,
        budget=5000,
    )

    print(f"\nMCTS Planning Results:")
    print(f"  Total steps: {len(sequence.steps)}")
    print(f"  Expected value: {sequence.total_value:.3f}")
    print(f"  Expected cost: ${sequence.expected_cost:.2f}")
    print(f"  Expected duration: {sequence.expected_duration / 3600:.1f} hours")

    print(f"\nPlanned experiment sequence:")
    for i, step in enumerate(sequence.steps[:3], 1):
        print(f"  Step {i}: {step.description}")
        print(f"    Sample size: {step.sample_size}")
        print(f"    Tests: {', '.join(step.statistical_tests)}")

    # =================================================================
    # PART 5: Bayesian Experimental Design
    # =================================================================

    print("\n" + "=" * 70)
    print("PART 5: Bayesian Experimental Design")
    print("=" * 70)

    selector = BayesianExperimentSelector(
        exploration_weight=1.0,
        cost_weight=0.3,
        use_thompson_sampling=True,
    )

    # Create experiment candidates
    candidates = [
        ExperimentCandidate(
            description="Increase model depth to 24 layers",
            parameters={"depth": 24, "heads": 12},
            uncertainty=0.85,
            expected_cost=800.0,
        ),
        ExperimentCandidate(
            description="Test with different attention patterns",
            parameters={"attention_type": "sparse", "sparsity": 0.5},
            uncertainty=0.90,
            expected_cost=600.0,
        ),
        ExperimentCandidate(
            description="Validate on different language tasks",
            parameters={"task": "translation", "language_pair": "en-de"},
            uncertainty=0.75,
            expected_cost=700.0,
        ),
        ExperimentCandidate(
            description="Analyze attention patterns across layers",
            parameters={"analysis_type": "layer_wise"},
            uncertainty=0.70,
            expected_cost=400.0,
        ),
        ExperimentCandidate(
            description="Compare with CNN-based models",
            parameters={"baseline": "resnet50"},
            uncertainty=0.80,
            expected_cost=500.0,
        ),
    ]

    # Select best experiments
    selected = await selector.select_experiments(
        candidates=candidates,
        prior_results=[result.execution],
        max_select=3,
    )

    print(f"\nBayesian Selection Results:")
    print(f"  Evaluated {len(candidates)} candidates")
    print(f"  Selected {len(selected)} experiments")

    print(f"\nSelected experiments (ranked by expected information gain):")
    for i, exp in enumerate(selected, 1):
        print(f"  {i}. {exp.description}")
        print(f"     EIG: {exp.expected_information_gain:.3f}")
        print(f"     Cost: ${exp.expected_cost:.2f}")
        print(f"     Explanation: {exp.information_gain_explanation}")

    # =================================================================
    # PART 6: Integration Demo - Full Pipeline
    # =================================================================

    print("\n" + "=" * 70)
    print("PART 6: Full Integration Pipeline")
    print("=" * 70)

    print("\nRunning integrated workflow:")
    print("  1. MCP literature search")
    print("  2. Thompson sampling for hypotheses")
    print("  3. MCTS for experiment planning")
    print("  4. Execute experiments")
    print("  5. Bayesian refinement selection")
    print("  6. Update knowledge graph")

    # This happens automatically in agent.run()
    integrated_result = await agent.run(
        "Test if increasing transformer width improves few-shot learning",
        interactive=False,
    )

    print(f"\n✓ Integrated workflow completed!")
    print(f"  Hypothesis tested: {integrated_result.planning.recommendation.hypothesis.statement[:60]}...")
    print(f"  Results: {integrated_result.analysis.summary[:100]}...")
    print(f"  Validation: {'✓ Approved' if integrated_result.validation.approved else '✗ Not approved'}")

    # Show refinements proposed by Bayesian design
    if integrated_result.refinements:
        print(f"\n  Refinements proposed (Bayesian design):")
        for i, ref in enumerate(integrated_result.refinements, 1):
            print(f"    {i}. {ref.description}")
            print(f"       EIG: {ref.expected_information_gain:.3f} | Cost: ${ref.cost:.2f}")

    # =================================================================
    # Summary
    # =================================================================

    print("\n" + "=" * 70)
    print("Demo Complete!")
    print("=" * 70)

    print("\nKey Features Demonstrated:")
    print("  ✓ MCP integration for real literature search")
    print("  ✓ Knowledge graph for scientific knowledge management")
    print("  ✓ Thompson sampling for efficient hypothesis exploration")
    print("  ✓ MCTS for optimal experiment sequence planning")
    print("  ✓ Bayesian experimental design for maximum information gain")
    print("  ✓ Full integration of all components")

    print("\nOutput Files:")
    print(f"  - knowledge_graph_visualization.png")
    print(f"  - ~/.sciagent/knowledge/knowledge_graph.pkl")

    print("\nNext Steps:")
    print("  1. Explore the knowledge graph visualization")
    print("  2. Run selected refinements")
    print("  3. Iterate on promising hypotheses")
    print("  4. Export knowledge graph for sharing")

    print()


async def demo_knowledge_graph_only():
    """
    Demo focused on knowledge graph capabilities
    """

    print("\n" + "=" * 70)
    print("Knowledge Graph Demo")
    print("=" * 70)

    kg = ScientificKnowledgeGraph()

    # Add some papers manually
    from sciagent.utils.models import Paper

    papers = [
        Paper(
            id="paper1",
            title="Attention Is All You Need",
            authors=["Vaswani et al."],
            abstract="We propose the Transformer...",
            year=2017,
            citations=50000,
        ),
        Paper(
            id="paper2",
            title="BERT: Pre-training of Deep Bidirectional Transformers",
            authors=["Devlin et al."],
            abstract="We introduce BERT...",
            year=2018,
            citations=40000,
        ),
    ]

    await kg.add_papers(papers)

    # Query
    results = kg.query_related_papers("transformer", limit=10)
    print(f"\nFound {len(results)} related papers")

    # Statistics
    stats = kg.get_statistics()
    print(f"\nKnowledge graph statistics:")
    for key, value in stats.items():
        print(f"  {key}: {value}")

    # Export
    kg.export_to_json(Path("knowledge_graph_export.json"))
    print(f"\n✓ Exported to knowledge_graph_export.json")


if __name__ == "__main__":
    # Run full demo
    asyncio.run(demo_full_workflow())

    # Uncomment for knowledge graph only demo
    # asyncio.run(demo_knowledge_graph_only())
